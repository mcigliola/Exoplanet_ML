{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c4c639-9dee-4d3f-9bed-7ebc53247bd9",
   "metadata": {},
   "source": [
    "# **1D Long Short-Term Memory (LSTM) Network**\n",
    "\n",
    "**LSTM networks are a type of recurrent neural network (RNN) designed to capture dependencies in sequential data. Unlike CNNs, which detect spacial patterns, LSTMs are well-suited for learning temporal relationships, making them ideal for analyzing light curves over time. By maintaining a memory of past observations, LSTMs can recognize trends and fluctuations that may indicate exoplanet transits.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb9e4d1-ac30-4bbc-9936-00fc23cacff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load preprocessed data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED) # Ensures consistent hashing\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Ensures deterministic TensorFlow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae20a32-0e9a-47fd-b44c-fdd022fa8eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3197\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m66,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3197\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,258</span> (469.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,258\u001b[0m (469.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,258</span> (469.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,258\u001b[0m (469.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)), # Input layer\n",
    "\n",
    "    LSTM(128, return_sequences=True, kernel_initializer=GlorotUniform(seed=42)), # LSTM layer capturing sequential patterns\n",
    "    Dropout(0.3), # Avoids overfitting\n",
    "\n",
    "    LSTM(64, return_sequences=False, kernel_initializer=GlorotUniform(seed=42)), # Reducing dimensions\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation=\"relu\", kernel_initializer=GlorotUniform(seed=42)), # Fully connected layer\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(2, activation=\"softmax\") # Output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d91146a-8b02-41c4-8e88-a9f0b500f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 3s/step - accuracy: 0.5234 - loss: 0.6915 - val_accuracy: 0.9439 - val_loss: 0.6808\n",
      "Epoch 2/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m963s\u001b[0m 3s/step - accuracy: 0.5196 - loss: 0.6899 - val_accuracy: 0.9614 - val_loss: 0.6704\n",
      "Epoch 3/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m983s\u001b[0m 3s/step - accuracy: 0.5248 - loss: 0.6874 - val_accuracy: 0.9912 - val_loss: 0.5764\n",
      "Epoch 4/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m998s\u001b[0m 3s/step - accuracy: 0.5006 - loss: 0.6962 - val_accuracy: 0.9912 - val_loss: 0.6906\n",
      "Epoch 5/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m989s\u001b[0m 3s/step - accuracy: 0.5046 - loss: 0.6926 - val_accuracy: 0.9912 - val_loss: 0.6899\n",
      "Epoch 6/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 3s/step - accuracy: 0.4975 - loss: 0.6929 - val_accuracy: 0.0123 - val_loss: 0.7076\n",
      "Epoch 7/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m996s\u001b[0m 3s/step - accuracy: 0.4952 - loss: 0.6928 - val_accuracy: 0.0140 - val_loss: 0.6948\n",
      "Epoch 8/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m997s\u001b[0m 3s/step - accuracy: 0.5007 - loss: 0.6921 - val_accuracy: 0.9193 - val_loss: 0.6886\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define parameters for early stopping to avoid overfitting\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Convert labels from {1, 2} to {0, 1}\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30, batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with open(\"history_lstm_baseline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "model.save(\"lstm_baseline.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6bd0a58-1d7a-4f97-b245-7735ae147c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 559ms/step - accuracy: 0.9708 - loss: 0.5824\n",
      "Test Accuracy: 0.9912\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 596ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       565\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       0.50      0.50      0.50       570\n",
      "weighted avg       0.98      0.99      0.99       570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predicted class labels (chooses the highest probability)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Selects class with highest probability\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79cac9-2d11-4600-85c4-1d0e51e84b34",
   "metadata": {},
   "source": [
    "## **Model Analysis**\n",
    "- **Architecture**: Single-directional LSTM with three convolutional layers.\n",
    "- **Regularization**: Batch normalization and dropout (`0.3`).\n",
    "- **Loss Function**: `sparse_categorical_crossentropy` with `softmax` activation.\n",
    "- **Optimization**: Adam optimizer with default learning rate.\n",
    "- **Early Stopping**: Enabled (`patience=5`), stopping at 8 epochs.\n",
    "\n",
    "### **Results**\n",
    "- **Overall Test Accuracy**: `99.12%`\n",
    "- **Precision for Label 2**: `0.00`\n",
    "- **Recall for Label 2**: `0.00`\n",
    "- **F1-Score for Label 2**: `0.00`\n",
    "\n",
    "### **Observations**\n",
    "The LSTM model failed to classify label 2 entirely.  \n",
    "\n",
    "### **Next Steps**\n",
    "- Adding higher weight to label 2 (`class_weights = {0: 1, 1: 5}`) should encourage the model to classify it better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dad86fb-fe07-443f-8f67-6cab65cc10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m986s\u001b[0m 3s/step - accuracy: 0.4971 - loss: 1.4440 - val_accuracy: 0.0193 - val_loss: 1.4991\n",
      "Epoch 2/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 3s/step - accuracy: 0.4976 - loss: 1.3678 - val_accuracy: 0.0211 - val_loss: 1.5436\n",
      "Epoch 3/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 3s/step - accuracy: 0.4953 - loss: 1.3890 - val_accuracy: 0.0105 - val_loss: 1.5496\n",
      "Epoch 4/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 3s/step - accuracy: 0.4983 - loss: 1.3662 - val_accuracy: 0.0123 - val_loss: 1.5467\n",
      "Epoch 5/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 3s/step - accuracy: 0.4955 - loss: 1.3640 - val_accuracy: 0.0123 - val_loss: 1.5606\n",
      "Epoch 6/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m986s\u001b[0m 3s/step - accuracy: 0.4945 - loss: 1.3703 - val_accuracy: 0.0105 - val_loss: 1.5756\n"
     ]
    }
   ],
   "source": [
    "# Add weight to class 1 (Label 2)\n",
    "class_weights = {0:1, 1:5}\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30, batch_size=32,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with open(\"history_lstm_weighted.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "model.save(\"lstm_weighted.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21e787d-2ecf-48d6-adcc-4839021d0585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 557ms/step - accuracy: 0.0400 - loss: 1.4726\n",
      "Test Accuracy: 0.0193\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 612ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       565\n",
      "           1       0.01      1.00      0.02         5\n",
      "\n",
      "    accuracy                           0.02       570\n",
      "   macro avg       0.50      0.51      0.02       570\n",
      "weighted avg       0.99      0.02      0.02       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predicted class labels (chooses the highest probability)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Selects class with highest probability\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f0939-5b12-4c42-9275-580881ea7357",
   "metadata": {},
   "source": [
    "## **Model Analysis**\n",
    "### **What Changed**\n",
    "- **Class Weights**: Class 1 (Label 2) assigned a weight of 5.\n",
    "\n",
    "### **Results**\n",
    "- **Overall Test Accuracy**: `1.93%`\n",
    "- **Precision for Label 2**: `0.01`\n",
    "- **Recall for Label 2**: `1.00`\n",
    "- **F1-Score for Label 2**: `0.02`\n",
    "\n",
    "### **Observations**\n",
    "The model overcompensated for Label 2, leading to nearly all samples being predicted as Label 2 and reducing accuracy drastically. Class weighting was too aggressive.  \n",
    "\n",
    "### **Next Steps**\n",
    "- Revert class weights and try increasing early stopping patience to give the model more time to learn from the training data before stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215292df-51c2-4339-a9e9-f668d2035810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3197\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m66,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3197\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,258</span> (469.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,258\u001b[0m (469.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,258</span> (469.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,258\u001b[0m (469.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model with reduced learning rate\n",
    "model_2 = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)), # Input layer\n",
    "\n",
    "    LSTM(128, return_sequences=True, kernel_initializer=GlorotUniform(seed=42)), # LSTM layer capturing sequential patterns\n",
    "    Dropout(0.3), # Avoids overfitting\n",
    "\n",
    "    LSTM(64, return_sequences=False, kernel_initializer=GlorotUniform(seed=42)), # Reducing dimensions\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation=\"relu\", kernel_initializer=GlorotUniform(seed=42)), # Fully connected layer\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(2, activation=\"softmax\") # Output\n",
    "])\n",
    "\n",
    "model_2.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bbe3f3-f7b0-4848-8faf-b1d1c2cf9bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m985s\u001b[0m 3s/step - accuracy: 0.5123 - loss: 0.6918 - val_accuracy: 0.9491 - val_loss: 0.6875\n",
      "Epoch 2/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m981s\u001b[0m 3s/step - accuracy: 0.5220 - loss: 0.6876 - val_accuracy: 0.9491 - val_loss: 0.6696\n",
      "Epoch 3/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 3s/step - accuracy: 0.5235 - loss: 0.6910 - val_accuracy: 0.0737 - val_loss: 0.7139\n",
      "Epoch 4/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 3s/step - accuracy: 0.5289 - loss: 0.6852 - val_accuracy: 0.7947 - val_loss: 0.6793\n",
      "Epoch 5/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m998s\u001b[0m 3s/step - accuracy: 0.5306 - loss: 0.6808 - val_accuracy: 0.1632 - val_loss: 0.7478\n",
      "Epoch 6/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 3s/step - accuracy: 0.5575 - loss: 0.6716 - val_accuracy: 0.7772 - val_loss: 0.5038\n",
      "Epoch 7/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1009s\u001b[0m 3s/step - accuracy: 0.5808 - loss: 0.6746 - val_accuracy: 0.9912 - val_loss: 0.5094\n",
      "Epoch 8/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 3s/step - accuracy: 0.4900 - loss: 0.7190 - val_accuracy: 0.9895 - val_loss: 0.6491\n",
      "Epoch 9/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 3s/step - accuracy: 0.5153 - loss: 0.6954 - val_accuracy: 0.8316 - val_loss: 0.6872\n",
      "Epoch 10/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 3s/step - accuracy: 0.5037 - loss: 0.6950 - val_accuracy: 0.0211 - val_loss: 0.7064\n",
      "Epoch 11/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 3s/step - accuracy: 0.5014 - loss: 0.6926 - val_accuracy: 0.0175 - val_loss: 0.7079\n",
      "Epoch 12/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 3s/step - accuracy: 0.5025 - loss: 0.6917 - val_accuracy: 0.0175 - val_loss: 0.7055\n",
      "Epoch 13/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m998s\u001b[0m 3s/step - accuracy: 0.4975 - loss: 0.6911 - val_accuracy: 0.0175 - val_loss: 0.7033\n",
      "Epoch 14/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 3s/step - accuracy: 0.5014 - loss: 0.6903 - val_accuracy: 0.0175 - val_loss: 0.7100\n",
      "Epoch 15/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1004s\u001b[0m 3s/step - accuracy: 0.5092 - loss: 0.6901 - val_accuracy: 0.0175 - val_loss: 0.6996\n",
      "Epoch 16/30\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1006s\u001b[0m 3s/step - accuracy: 0.5128 - loss: 0.6892 - val_accuracy: 0.0175 - val_loss: 0.7065\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Increased patience for early stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model_2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30, batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with open(\"history_lstm_patient.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "model_2.save(\"lstm_patient.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8123ac-6da1-4448-aebd-f914ed3263a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 553ms/step - accuracy: 0.7723 - loss: 0.5172\n",
      "Test Accuracy: 0.7772\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 643ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87       565\n",
      "           1       0.02      0.60      0.05         5\n",
      "\n",
      "    accuracy                           0.78       570\n",
      "   macro avg       0.51      0.69      0.46       570\n",
      "weighted avg       0.99      0.78      0.87       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model_2.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predicted class labels (chooses the highest probability)\n",
    "y_pred = model_2.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Selects class with highest probability\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083184f-3507-45b8-8cf4-16ceaae81dce",
   "metadata": {},
   "source": [
    "## **Model Analysis**\n",
    "### **What Changed**\n",
    "- **Removed Weights**: Class weights reverted to {0:1, 1:1}.\n",
    "- **Early Stopping**: Enabled (`patience=10`), stopping at 16 epochs.\n",
    "  \n",
    "### **Results**\n",
    "- **Overall Test Accuracy**: `77.72%`\n",
    "- **Precision for Label 2**: `0.02`\n",
    "- **Recall for Label 2**: `0.60`\n",
    "- **F1-Score for Label 2**: `0.05`\n",
    "\n",
    "### **Observations**\n",
    "Increasing early stopping patienced improved recall for Label 2, however there is still a big imbalance. F1-score for Label 2 is only 0.05 because of very low precision. \n",
    "\n",
    "### **Next Steps**\n",
    "- False positives for Label 2 need to be reduced.  Lowering the decision threshold may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcfc616c-3eec-43d6-ac07-f83a3f764fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 477ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87       565\n",
      "           1       0.02      0.60      0.05         5\n",
      "\n",
      "    accuracy                           0.78       570\n",
      "   macro avg       0.51      0.69      0.46       570\n",
      "weighted avg       0.99      0.78      0.87       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lower default decision threshold from 0.5 to 0.3.\n",
    "\n",
    "# Get predicted class labels (chooses the highest probability)\n",
    "y_pred = model_2.predict(X_test)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred_adjusted = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74704f1d-2149-479c-8a1e-31fbae1885c3",
   "metadata": {},
   "source": [
    "## **Model Analysis**\n",
    "### **What Changed**\n",
    "- **Lowered Decision Threshold**: Class weights reverted to {0:1, 1:1}.\n",
    "  \n",
    "### **Results**\n",
    "- **Precision for Label 2**: `0.02`\n",
    "- **Recall for Label 2**: `0.60`\n",
    "- **F1-Score for Label 2**: `0.05`\n",
    "\n",
    "### **Observations**\n",
    "Lowering the decision threshold did not change the performance of the model at all. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b294b5b-cc09-4c54-906d-24a67291e216",
   "metadata": {},
   "source": [
    "## **Project Conclusions**\n",
    "\n",
    "This project explored data preparation steps and the training of two deep learning architectures - 1D Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks - to classify exoplanet candidates based on flux data. The CNN models focused on pattern detection within the light curves, while the LSTM models aimed to capture temporal dependencies.  The raw data was heavily imbalanced with Label 2 (exoplanet stars) samples representing only a tiny fraction of the total samples. To mitigate this imbalance, the Synthetic Minority Oversampling Technique (SMOTE) was applied and the data was normalized and reshaped for use in training. Despite training that involved tuning paramaters such as regularization, dropout, learning rate, class weighting, and early stopping, both architectures struggled to achieve strong generalization, particularly in identifying the minority class. The LSTM performed slightly better in recall for Label 2, but at the expense of overall accuracy. The CNN maintained higher precision, but failed to distiguish Label 2 samples effectively.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Suggested Next Steps** (Outside the scope of this project)\n",
    "- **Feature Engineering**: Extract additional time-series features, such as periodicity, to enhance model interpretability.\n",
    "- **Alternative Architectures**: Experiment with hybrid models that combine CNNs for pattern detection and LSTMs for sequence learning.\n",
    "- **Hyperparameter Optimization**: Conduct a more exhaustive exploration of hyperparameter optimizations.\n",
    "- **Domain Specific Techniques**: Explore astrophysics-informed methods such as phase-folding or transit fitting to improve signal extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6bc97-b6f4-4f10-bbca-03bdee36ec93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
